{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3d5c9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üöÄ PREPROCESSING PIPELINE - MODE: TEST\n",
      "============================================================\n",
      "\n",
      "‚úÖ R√®gles charg√©es depuis preprocessing_rules.pkl\n",
      "‚úÖ Donn√©es test charg√©es\n",
      "‚úÖ Sport trait√© (31 big clubs)\n",
      "‚úÖ Tenure et Retired trait√©s\n",
      "‚úÖ Job trait√©\n",
      "‚úÖ INSEE trait√© (88 big cities)\n",
      "‚úÖ Densit√© et Revenus trait√©s\n",
      "‚úÖ Pension et Former Jobs trait√©s\n",
      "‚úÖ DVF trait√©\n",
      "‚úÖ Working hours imput√© (cascade)\n",
      "‚úÖ Ind√©pendants imput√©s (4797 individus)\n",
      "‚úÖ Patches finaux appliqu√©s\n",
      "‚úÖ Cat√©gories rares nettoy√©es\n",
      "‚úÖ Dataset sauvegard√©: test_processed.csv\n",
      "\n",
      "============================================================\n",
      "‚úÖ PREPROCESSING TERMIN√â - 50045 lignes, 46 colonnes\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from Part1 import DataPreprocessor  \n",
    "\n",
    "# Ici, le code de Part1 ne s'est PAS lanc√© (gr√¢ce au if __name__ == \"__main__\")\n",
    "# Tu peux maintenant utiliser l'outil proprement :\n",
    "prepro_test = DataPreprocessor(mode='test')\n",
    "prepro_test.run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6988b50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üöÄ PREPROCESSING PIPELINE - MODE: TEST\n",
      "============================================================\n",
      "\n",
      "‚úÖ R√®gles charg√©es depuis preprocessing_rules.pkl\n",
      "‚úÖ Donn√©es test charg√©es\n",
      "‚úÖ Sport trait√© (31 big clubs)\n",
      "‚úÖ Tenure et Retired trait√©s\n",
      "‚úÖ Job trait√©\n",
      "‚úÖ INSEE trait√© (88 big cities)\n",
      "‚úÖ Densit√© et Revenus trait√©s\n",
      "‚úÖ Pension et Former Jobs trait√©s\n",
      "‚úÖ DVF trait√©\n",
      "‚úÖ Working hours imput√© (cascade)\n",
      "‚úÖ Ind√©pendants imput√©s (4797 individus)\n",
      "‚úÖ Patches finaux appliqu√©s\n",
      "‚úÖ Cat√©gories rares nettoy√©es\n",
      "‚úÖ Dataset sauvegard√©: test_processed.csv\n",
      "\n",
      "============================================================\n",
      "‚úÖ PREPROCESSING TERMIN√â - 50045 lignes, 46 colonnes\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l0/l3b41n5n00z588bsfcg0b5040000gn/T/ipykernel_59392/2469918311.py:30: DtypeWarning: Columns (4,20,27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_train = pd.read_csv('train_processed.csv')\n",
      "/var/folders/l0/l3b41n5n00z588bsfcg0b5040000gn/T/ipykernel_59392/2469918311.py:31: DtypeWarning: Columns (4,19,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_test = pd.read_csv('test_processed.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File generated: predictions.csv\n",
      "Total predictions: 50045\n",
      "Class distribution:\n",
      "target\n",
      "L    55.392147\n",
      "T    44.607853\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from Part1 import DataPreprocessor \n",
    "\n",
    "# ==============================================================================\n",
    "# CONFIGURATION & PARAMETERS\n",
    "# ==============================================================================\n",
    "best_params = {\n",
    "    'n_estimators': 150,\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.1,\n",
    "    'scale_pos_weight': 1.2,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': 2,\n",
    "    'eval_metric': 'logloss',\n",
    "    'tree_method': 'hist'\n",
    "}\n",
    "\n",
    "# ==============================================================================\n",
    "# DATA PREPARATION\n",
    "# ==============================================================================\n",
    "\n",
    "# Run Preprocessing on Test Set\n",
    "processor_test = DataPreprocessor(mode='test')\n",
    "processor_test.run_pipeline()\n",
    "\n",
    "# Load Data\n",
    "df_train = pd.read_csv('train_processed.csv')\n",
    "df_test = pd.read_csv('test_processed.csv')\n",
    "test_ids = df_test['UNIQUE_ID']\n",
    "\n",
    "# Target Encoding\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(df_train['target'])\n",
    "\n",
    "# Drop technical columns\n",
    "cols_drop = ['UNIQUE_ID', 'Insee', 'work_desc', 'former_work_desc', 'target']\n",
    "X_train = df_train.drop(columns=[c for c in cols_drop if c in df_train.columns])\n",
    "X_test = df_test.drop(columns=[c for c in cols_drop if c in df_test.columns])\n",
    "\n",
    "# Unified Categorical Encoding\n",
    "len_train = len(X_train)\n",
    "X_all = pd.concat([X_train, X_test], axis=0).reset_index(drop=True)\n",
    "\n",
    "cats = X_all.select_dtypes(include=['object', 'category']).columns\n",
    "for col in cats:\n",
    "    X_all[col] = X_all[col].astype('category').cat.codes\n",
    "\n",
    "X_all = X_all.fillna(-1)\n",
    "\n",
    "# Resplit\n",
    "X_train_final = X_all.iloc[:len_train, :]\n",
    "X_test_final = X_all.iloc[len_train:, :]\n",
    "\n",
    "# ==============================================================================\n",
    "# FINAL TRAINING & PREDICTION\n",
    "# ==============================================================================\n",
    "\n",
    "# Fit on full training set\n",
    "model = xgb.XGBClassifier(**best_params)\n",
    "model.fit(X_train_final, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "preds_encoded = model.predict(X_test_final)\n",
    "preds_labels = le.inverse_transform(preds_encoded)\n",
    "\n",
    "# Create submission dataframe\n",
    "df_final = pd.DataFrame({\n",
    "    'UNIQUE_ID': test_ids,\n",
    "    'target': preds_labels\n",
    "})\n",
    "\n",
    "filename = \"predictions.csv\"\n",
    "df_final.to_csv(filename, index=False)\n",
    "\n",
    "# ==============================================================================\n",
    "# FINAL CHECK\n",
    "# ==============================================================================\n",
    "print(f\"File generated: {filename}\")\n",
    "print(f\"Total predictions: {len(df_final)}\")\n",
    "print(\"Class distribution:\")\n",
    "print(df_final['target'].value_counts(normalize=True) * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cours_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
